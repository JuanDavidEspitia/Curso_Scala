{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigdata: Scala + Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/BigData.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición:\n",
    "\n",
    "Conjunto de Datos caracterizado por su volumen, velocidad y variedad (VVV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beneficios:\n",
    "\n",
    "- Análisis de Datos\n",
    "- ETL(Extracción, transfomación y carga)**\n",
    "- Streaming\n",
    "- Procesamiento\n",
    "- Machine learnig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL (Extract, Transform and Load)\n",
    "\n",
    "Es el proceso que permite a las organizaciones mover datos desde múltiples fuentes, reformatearlos y limpiarlos, y cargarlos en otra base de datos, data mart, o data warehouse para analizar, o en otro sistema operacional para apoyar un proceso de negocio.\n",
    "\n",
    "Nos perminte la integración de datos. En Bigdata podemos las podemos construir:\n",
    "\n",
    "1. **Orquestador**\n",
    "2. **Scala**\n",
    "3. **Spark**\n",
    "4. **Herramientas de integración Continua.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tools-bigdata-scala.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Orquestador\n",
    "\n",
    "Nos permite la contrucción y control del flujo de trabajo. Actualmente existen varios automatizadores de estos flujos que se puede usar según las necesidades Ej:\n",
    "\n",
    "- Apache Airflow\n",
    "- Apache kafka\n",
    "- Apahe Oozie\n",
    "- AWS Step Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leguaje que aprovecha la combinación de la programción orientada a objetos y la programación funcional. Similar a Java. Su demanda ha aumentado en los últimos años. A continuación realizaremos una pequeña introducción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a: Int = 1\r\n",
       "b: Int = 2\r\n",
       "c: Int = 3\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a: Int = 1\n",
    "val b = 2 //inmutable\n",
    "var c = 3 //mutable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "26: error: reassignment to val\r",
     "output_type": "error",
     "traceback": [
      "<console>:26: error: reassignment to val\r",
      "       b = 5\r",
      "         ^",
      ""
     ]
    }
   ],
   "source": [
    "b = 5 // No se puede alterar su valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d: String = hola mundo\r\n",
       "e: Char = e\r\n",
       "f: Double = 123.4\r\n",
       "g: Int = -5678\r\n",
       "h: Boolean = true\r\n",
       "i: Array[String] = Array(x, y, z)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val d = \"hola mundo\"\n",
    "val e = 'e'\n",
    "val f = 123.4\n",
    "val g = -5678\n",
    "val h = true\n",
    "val i = Array(\"x\",\"y\", \"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases y Objetos\n",
    "\n",
    "\n",
    "<img src=\"images/clases-objetos.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Point\r\n",
       "defined object Demo\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Point(val xc: Int, val yc: Int) {\n",
    "   var xf: Int = xc\n",
    "   var yf: Int = yc\n",
    "   \n",
    "   def move() {\n",
    "      println(\"Point x location : \" + xf)\n",
    "      println(\"Point y location : \" + yf) \n",
    "   }\n",
    "}\n",
    "\n",
    "object Demo {\n",
    "   def main() {\n",
    "      val pt = new Point(10, 20)\n",
    "      pt.move();\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point x location : 10\n",
      "Point y location : 20\n"
     ]
    }
   ],
   "source": [
    "Demo.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operadores Aritmeticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + y: 30\n",
      "x - y: -10\n",
      "x * y: 200\n",
      "x / y: 0\n",
      "x % y: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x: Int = 10\r\n",
       "y: Int = 20\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x = 10\n",
    "var y = 20\n",
    "println(\"x + y: \" + (x + y) )\n",
    "println(\"x - y: \" + (x - y) )\n",
    "println(\"x * y: \" + (x * y) )\n",
    "println(\"x / y: \" + (x / y) )\n",
    "println(\"x % y: \" + (x % y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operadores Relacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x es igual que y: false\n",
      "x es diferente que y: true\n",
      "x es mayor que y: true\n",
      "x es menor que y: false\n",
      "x es mayor o igual que y: true\n",
      "x es menor o igual que y: false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x: Int = 50\r\n",
       "y: Int = 25\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x = 50\n",
    "var y = 25\n",
    "\n",
    "println(\"x es igual que y: \" + (x == y) )\n",
    "println(\"x es diferente que y: \" + (x != y) )\n",
    "println(\"x es mayor que y: \" + (x > y) )\n",
    "println(\"x es menor que y: \" + (x < y) )\n",
    "println(\"x es mayor o igual que y: \" + (x >= y) )\n",
    "println(\"x es menor o igual que y: \" + (x <= y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operadores Logicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x AND y: false\n",
      "x OR y: true\n",
      "NOT x : false\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x: Boolean = true\r\n",
       "y: Boolean = false\r\n",
       "z: Boolean = false\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x = true\n",
    "var y = false\n",
    "var z = false\n",
    "\n",
    "println(\"x AND y: \" + (x && y) )\n",
    "println(\"x OR y: \" + (x || y) )\n",
    "println(\"NOT x : \" + (!x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = x + 2 = 3"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x: Int = 3\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x = 1\n",
    "x += 2 \n",
    "print(\"x = x + 2 = \" + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aprobado\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x: Double = 2.95\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var x = 2.95\n",
    "if( x >= 2.95 ) println(\"Aprobado\")\n",
    " else println(\"Reprobado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Switch Case en Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y: Int = 1\r\n",
       "res6: String = Uno\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var y = 1\n",
    "\n",
    "y match {\n",
    "   case 1 => \"Uno\"\n",
    "   case 2 => \"Dos\"\n",
    "   case 3 => \"Tres\"\n",
    "   case 4 => \"Cuatro\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de x: 1\n",
      "Valor de x: 2\n",
      "Valor de x: 3\n",
      "Valor de x: 4\n",
      "Valor de x: 5\n",
      "Valor de x: 6\n",
      "Valor de x: 7\n",
      "Valor de x: 8\n",
      "Valor de x: 9\n"
     ]
    }
   ],
   "source": [
    "for( x <- 1 until 10){\n",
    "    println( \"Valor de x: \" + x );\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de x: 1\n",
      "Valor de x: 2\n",
      "Valor de x: 3\n",
      "Valor de x: 4\n",
      "Valor de x: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "xList: List[Int] = List(1, 2, 3, 4, 5)\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xList = List(1,2,3,4,5)\n",
    "\n",
    "for( x <- xList ){\n",
    "    println( \"Valor de x: \" + x )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emptyDf: org.apache.spark.sql.DataFrame = []\r\n",
       "namesDf: org.apache.spark.sql.DataFrame = [first_name: string, last_name: string]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// crear un Dataframe son inmutables\n",
    "val emptyDf = spark.emptyDataFrame\n",
    "val namesDf = Seq((\"Juan\", \"Perez\"),(\"Andres\" , \"Rueda\")).toDF(\"first_name\", \"last_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n",
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|      Juan|    Perez|\n",
      "|    Andres|    Rueda|\n",
      "+----------+---------+\n",
      "\n",
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|      Juan|    Perez|\n",
      "+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// ver data \n",
    "emptyDf.show()\n",
    "namesDf.show()\n",
    "namesDf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "\n",
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// ver estructura\n",
    "emptyDf.printSchema()\n",
    "namesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: Array[String] = Array(first_name, last_name)\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// ver columnas\n",
    "namesDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "world_happiness: org.apache.spark.sql.DataFrame = [Country name: string, Regional indicator: string ... 18 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// CSV a Dataframe\n",
    "val world_happiness = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \",\").load(\"input/2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Cantidad de registros ---------------\n",
      "153\n",
      "--------------- Estructura del DF ---------------\n",
      "root\n",
      " |-- Country name: string (nullable = true)\n",
      " |-- Regional indicator: string (nullable = true)\n",
      " |-- Ladder score: string (nullable = true)\n",
      " |-- Standard error of ladder score: string (nullable = true)\n",
      " |-- upperwhisker: string (nullable = true)\n",
      " |-- lowerwhisker: string (nullable = true)\n",
      " |-- Logged GDP per capita: string (nullable = true)\n",
      " |-- Social support: string (nullable = true)\n",
      " |-- Healthy life expectancy: string (nullable = true)\n",
      " |-- Freedom to make life choices: string (nullable = true)\n",
      " |-- Generosity: string (nullable = true)\n",
      " |-- Perceptions of corruption: string (nullable = true)\n",
      " |-- Ladder score in Dystopia: string (nullable = true)\n",
      " |-- Explained by: Log GDP per capita: string (nullable = true)\n",
      " |-- Explained by: Social support: string (nullable = true)\n",
      " |-- Explained by: Healthy life expectancy: string (nullable = true)\n",
      " |-- Explained by: Freedom to make life choices: string (nullable = true)\n",
      " |-- Explained by: Generosity: string (nullable = true)\n",
      " |-- Explained by: Perceptions of corruption: string (nullable = true)\n",
      " |-- Dystopia + residual: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Imprimimos la cantidad de registros\n",
    "println(\"--------------- Cantidad de registros ---------------\")\n",
    "println(world_happiness.count())\n",
    "println(\"--------------- Estructura del DF ---------------\")\n",
    "world_happiness.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-----------------------+\n",
      "|  Country name|  Regional indicator|Healthy life expectancy|\n",
      "+--------------+--------------------+-----------------------+\n",
      "|       Finland|      Western Europe|             71.9008255|\n",
      "|       Denmark|      Western Europe|            72.40250397|\n",
      "|   Switzerland|      Western Europe|            74.10244751|\n",
      "|       Iceland|      Western Europe|                     73|\n",
      "|        Norway|      Western Europe|            73.20078278|\n",
      "|   Netherlands|      Western Europe|            72.30091858|\n",
      "|        Sweden|      Western Europe|            72.60076904|\n",
      "|   New Zealand|North America and...|            73.20262909|\n",
      "|       Austria|      Western Europe|            73.00250244|\n",
      "|    Luxembourg|      Western Europe|            72.59999847|\n",
      "|        Canada|North America and...|            73.60160065|\n",
      "|     Australia|North America and...|            73.60453796|\n",
      "|United Kingdom|      Western Europe|            72.30160522|\n",
      "|        Israel|Middle East and N...|            73.20025635|\n",
      "|    Costa Rica|Latin America and...|            71.29985046|\n",
      "|       Ireland|      Western Europe|            72.30078888|\n",
      "|       Germany|      Western Europe|            72.20201874|\n",
      "| United States|North America and...|            68.29949951|\n",
      "|Czech Republic|Central and Easte...|            70.04793549|\n",
      "|       Belgium|      Western Europe|            72.00164795|\n",
      "+--------------+--------------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "expectancy_life_healty_sin_cast: org.apache.spark.sql.DataFrame = [Country name: string, Regional indicator: string ... 1 more field]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val expectancy_life_healty_sin_cast = world_happiness.select(\n",
    "    $\"Country name\",\n",
    "    $\"Regional indicator\",\n",
    "    $\"Healthy life expectancy\"\n",
    ")\n",
    "expectancy_life_healty_sin_cast.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|  Country name|\n",
      "+--------------+\n",
      "|       Finland|\n",
      "|       Denmark|\n",
      "|   Switzerland|\n",
      "|       Iceland|\n",
      "|        Norway|\n",
      "|   Netherlands|\n",
      "|        Sweden|\n",
      "|   New Zealand|\n",
      "|       Austria|\n",
      "|    Luxembourg|\n",
      "|        Canada|\n",
      "|     Australia|\n",
      "|United Kingdom|\n",
      "|        Israel|\n",
      "|    Costa Rica|\n",
      "|       Ireland|\n",
      "|       Germany|\n",
      "| United States|\n",
      "|Czech Republic|\n",
      "|       Belgium|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------------------+\n",
      "|Healthy life expectancy|\n",
      "+-----------------------+\n",
      "|            67.69958496|\n",
      "+-----------------------+\n",
      "\n",
      "+------------+-----------------------+\n",
      "|Country name|Healthy life expectancy|\n",
      "+------------+-----------------------+\n",
      "|    Colombia|            67.69958496|\n",
      "+------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\r\n",
       "expectancy_life: org.apache.spark.sql.DataFrame = [Country name: string, Regional indicator: string ... 1 more field]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// filtrar y seleccionar en un dataframe\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "// Imprimmos los valores la columna seleccionada\n",
    "world_happiness.select($\"Country name\").show()\n",
    "\n",
    "val expectancy_life = world_happiness.select(\n",
    "    $\"Country name\",\n",
    "    $\"Regional indicator\",\n",
    "    $\"Healthy life expectancy\".cast(\"double\")\n",
    ")\n",
    "\n",
    "world_happiness.filter(\n",
    "    $\"Country name\" === \"Colombia\" \n",
    ").select(\n",
    "    $\"Healthy life expectancy\"\n",
    ").show()\n",
    "\n",
    "world_happiness.filter(\n",
    "    $\"Country name\" === \"Colombia\"\n",
    ").select(\n",
    "    $\"Country name\",\n",
    "    $\"Healthy life expectancy\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country name: string (nullable = true)\n",
      " |-- Regional indicator: string (nullable = true)\n",
      " |-- Healthy life expectancy: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expectancy_life.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-----+\n",
      "|Regional indicator                |count|\n",
      "+----------------------------------+-----+\n",
      "|South Asia                        |7    |\n",
      "|Middle East and North Africa      |17   |\n",
      "|North America and ANZ             |4    |\n",
      "|Sub-Saharan Africa                |39   |\n",
      "|East Asia                         |6    |\n",
      "|Commonwealth of Independent States|12   |\n",
      "|Latin America and Caribbean       |21   |\n",
      "|Western Europe                    |21   |\n",
      "|Central and Eastern Europe        |17   |\n",
      "|Southeast Asia                    |9    |\n",
      "+----------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// agrupaciones\n",
    "expectancy_life.groupBy($\"Regional indicator\").count().show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+-------------------+\n",
      "|Regional indicator                |max life expectancy|\n",
      "+----------------------------------+-------------------+\n",
      "|South Asia                        |70.59999847        |\n",
      "|Middle East and North Africa      |73.20025635        |\n",
      "|North America and ANZ             |73.60453796        |\n",
      "|Sub-Saharan Africa                |66.40434265        |\n",
      "|East Asia                         |76.77170563        |\n",
      "|Commonwealth of Independent States|66.75065613        |\n",
      "|Latin America and Caribbean       |71.29985046        |\n",
      "|Western Europe                    |74.40270996        |\n",
      "|Central and Eastern Europe        |71.1029892         |\n",
      "|Southeast Asia                    |76.80458069        |\n",
      "+----------------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Agrupamos por Regional Indicator \n",
    "expectancy_life.groupBy(\n",
    "    $\"Regional indicator\"\n",
    ").agg(\n",
    "    max($\"Healthy life expectancy\").as(\"max life expectancy\")\n",
    ").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-----------------------+----+\n",
      "|  Country name|  Regional indicator|Healthy life expectancy|year|\n",
      "+--------------+--------------------+-----------------------+----+\n",
      "|       Finland|      Western Europe|             71.9008255|2020|\n",
      "|       Denmark|      Western Europe|            72.40250397|2020|\n",
      "|   Switzerland|      Western Europe|            74.10244751|2020|\n",
      "|       Iceland|      Western Europe|                   73.0|2020|\n",
      "|        Norway|      Western Europe|            73.20078278|2020|\n",
      "|   Netherlands|      Western Europe|            72.30091858|2020|\n",
      "|        Sweden|      Western Europe|            72.60076904|2020|\n",
      "|   New Zealand|North America and...|            73.20262909|2020|\n",
      "|       Austria|      Western Europe|            73.00250244|2020|\n",
      "|    Luxembourg|      Western Europe|            72.59999847|2020|\n",
      "|        Canada|North America and...|            73.60160065|2020|\n",
      "|     Australia|North America and...|            73.60453796|2020|\n",
      "|United Kingdom|      Western Europe|            72.30160522|2020|\n",
      "|        Israel|Middle East and N...|            73.20025635|2020|\n",
      "|    Costa Rica|Latin America and...|            71.29985046|2020|\n",
      "|       Ireland|      Western Europe|            72.30078888|2020|\n",
      "|       Germany|      Western Europe|            72.20201874|2020|\n",
      "| United States|North America and...|            68.29949951|2020|\n",
      "|Czech Republic|Central and Easte...|            70.04793549|2020|\n",
      "|       Belgium|      Western Europe|            72.00164795|2020|\n",
      "+--------------+--------------------+-----------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "expectancy_life_2020: org.apache.spark.sql.DataFrame = [Country name: string, Regional indicator: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//agregar columna\n",
    "val expectancy_life_2020 = expectancy_life.withColumn(\"year\",lit(\"2020\").cast(\"Integer\"))\n",
    "expectancy_life_2020.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citiesDf: org.apache.spark.sql.DataFrame = [Country name: string, City: string]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val citiesDf = Seq((\"Colombia\", \"Bogota\"),(\"Colombia\" , \"Medellin\")).toDF(\"Country name\", \"City\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+\n",
      "| country|            regional|    City|\n",
      "+--------+--------------------+--------+\n",
      "|Colombia|Latin America and...|Medellin|\n",
      "|Colombia|Latin America and...|  Bogota|\n",
      "+--------+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "citiesAndCountries: org.apache.spark.sql.DataFrame = [country: string, regional: string ... 1 more field]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// join pueden ser inner, left, right, outer, leftsemi, leftanti\n",
    "val citiesAndCountries = expectancy_life_2020.as(\"table1\").join(\n",
    "    citiesDf.as(\"table2\"), \n",
    "    $\"table1.Country name\" === $\"table2.Country name\",\n",
    "    \"inner\"\n",
    ").select(\n",
    "    $\"table1.Country name\".as(\"country\"),\n",
    "    $\"table1.Regional indicator\".as(\"regional\"),\n",
    "    $\"table2.City\"\n",
    ")\n",
    "\n",
    "\n",
    "citiesAndCountries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.ClassNotFoundException",
     "evalue": " Failed to find data source: org.apache.spark.sql.avro.AvroFileFormat. Please find packages at http://spark.apache.org/third-party-projects.html\r",
     "output_type": "error",
     "traceback": [
      "java.lang.ClassNotFoundException: Failed to find data source: org.apache.spark.sql.avro.AvroFileFormat. Please find packages at http://spark.apache.org/third-party-projects.html\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:657)\r",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:245)\r",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\r",
      "  ... 40 elided\r",
      "Caused by: java.lang.ClassNotFoundException: org.apache.spark.sql.avro.AvroFileFormat.DefaultSource\r",
      "  at scala.reflect.internal.util.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:62)\r",
      "  at java.lang.ClassLoader.loadClass(Unknown Source)\r",
      "  at java.lang.ClassLoader.loadClass(Unknown Source)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20$$anonfun$apply$12.apply(DataSource.scala:634)\r",
      "  at scala.util.Try$.apply(Try.scala:192)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$20.apply(DataSource.scala:634)\r",
      "  at scala.util.Try.orElse(Try.scala:84)\r",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:634)\r",
      "  ... 42 more",
      ""
     ]
    }
   ],
   "source": [
    "//Escribir CSV, avro o parquet \n",
    "citiesAndCountries.write.mode(\"overwrite\").parquet(\"parquet\")\n",
    "citiesAndCountries.write.format(\"com.databricks.spark.avro\").mode(\"overwrite\").save(\"avro\")\n",
    "citiesAndCountries.write.option(\"header\", \"true\").csv(\"CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle\n",
    "\n",
    "La redistribución de cargas en diferentes nodos o diferentes maquinas. el uso de join, groupBy aumentan estas reparticiones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buenas prácticas\n",
    "\n",
    "- Validar el comportamiento de dataframes con el uso del comando explain(). Spark 3 mejora esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [Country name#34 AS country#278, Regional indicator#35 AS regional#279, City#234]\n",
      "+- *(1) BroadcastHashJoin [Country name#34], [Country name#233], Inner, BuildRight\n",
      "   :- *(1) Project [Country name#34, Regional indicator#35]\n",
      "   :  +- *(1) Filter isnotnull(Country name#34)\n",
      "   :     +- *(1) FileScan csv [Country name#34,Regional indicator#35] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/jespitiaa/Curso_Scala/input/2020.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Country name)], ReadSchema: struct<Country name:string,Regional indicator:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "      +- LocalTableScan [Country name#233, City#234]\n"
     ]
    }
   ],
   "source": [
    "citiesAndCountries.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conocer las herramientas con las que trabajas y validar en lo posible las configuraciones de spark: http://spark.apache.org/docs/latest/sql-performance-tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@5e2b623\r\n",
       "res23: String = 10485760\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "sqlContext.getConf(\"spark.sql.shuffle.partitions\")\n",
    "sqlContext.getConf(\"spark.sql.autoBroadcastJoinThreshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evitar el uso del count() a menos que sea necesario retornar el número de filas.\n",
    "- Cuando se requiere agrupar analizar cuál función utilizar: groupBy, groupByKey, reduceByKey, TreeReduce/TreeAggregate\n",
    "- Al realizar Join validar data para utilizar estrategias como: broadcast, Sort Merge, Shuffle Hash o Cartesian. Spark 3 a optimizado el uso de estas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citiesAndCountries: org.apache.spark.sql.DataFrame = [country: string, regional: string ... 1 more field]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val citiesAndCountries = expectancy_life_2020.as(\"table1\").join(\n",
    "    broadcast(citiesDf).as(\"table2\"), \n",
    "    $\"table1.Country name\" === $\"table2.Country name\",\n",
    "    \"inner\"\n",
    ").select(\n",
    "    $\"table1.Country name\".as(\"country\"),\n",
    "    $\"table1.Regional indicator\".as(\"regional\"),\n",
    "    $\"table2.City\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dependiendo de la complejidad de transformaciones y recursos puede guardar algunos datos en memoria. https://sparkbyexamples.com/spark/spark-dataframe-cache-and-persist-explained/\n",
    "- Serializar es importante en aplicaciones distribuidas.\n",
    "- Evitar el uso del crossjoin.\n",
    "- comunicación de equipo (data engineer, arquitectos, devops, cientificos, gobierno de datos )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
